# Predicting Cyberbullying on Tweet Data
This project sought to compare the performance of different machine learning algorithms to predict whether or not a tweet should be classified as cyberbullying. This was completed as a course final project in December 2022.

## Problem Statement
In the age of the internet and social media, online discourse is now widespread and is an integral part to many people's lives. While there are many benefits to this highly accessible means of communication, one unfortunate side effect is the rise of cyberbullying. In order to create a welcoming environment, it is important to be able to moderate excessively harmful and negative comments. The sheer amount of users for a single social media platform, such as Facebook or Twitter, makes this problem ideal for machine learning. Where human moderators can only look over so much content, a machine learning algorithm properly trained in natural language processing can cover vast amounts of data. There are many forms of content on the internet (e.g. videos, photos, comments, etc) but this project focuses solely on text content. The [dataset](https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data) used in this project is composed of over 40,000 tweets that have already been classified as cyberbullying or not. Because the scope of this project is limited to text data, this problem can be considered a natural language processing problem. There are currently many state of the art natural language processing algorithms, such as BERT. The challenge then lies in how we can fine-tune such algorithms to accurately classify content as cyberbullying or not.

## Solution Methodology
For this project, we compared various combinations of encoders and classification models. For encoding, we tested one-hot and stemming encoders, which both represents words as mathematical vectors. The difference between the two is that stemming encoders also clean up and shorten words to the root stem in order to make it computationally lighter. For classification, we used a naive bayesian model as the baseline model. We also used logistic regression, random forests, and XGBoost. Lastly, we fine-tuned pretrained BERT models and compared their performance to our other models.

## Results
The code for this problem can not currently be provided. When using one-hot or stemming encoders, the naive Bayeian model performed the worst and the XGBoost model performed the best. For the BERT models, models that took letter capitalization into account performed better than their counterparts that do not make such distinctions. For a more detailed explanation of this project, please refer to [Predicting Cyberbullying Report.pdf](https://github.com/cyoo28/predicting-cyberbullying/blob/main/Predicting%20Cyberbullying%20Report.pdf).
